{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6bab96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\tejas\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56bd46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\tejas\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\tejas\\anaconda3\\lib\\site-packages (0.20.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\tejas\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fba7e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                       # for working with files\n",
    "import numpy as np              # for numerical computationss\n",
    "import pandas as pd             # for working with dataframes\n",
    "import torch                    # Pytorch module \n",
    "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
    "import torch.nn as nn           # for creating  neural networks\n",
    "from torch.utils.data import DataLoader # for dataloaders \n",
    "from PIL import Image           # for checking images\n",
    "import torch.nn.functional as F # for functions for calculating loss\n",
    "import torchvision.transforms as transforms   # for transforming images into tensors \n",
    "from torchvision.utils import make_grid       # for data checking\n",
    "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
    "from torchsummary import summary\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a300285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70295 images belonging to 38 classes.\n",
      "Found 17572 images belonging to 38 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejas\\anaconda3\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - accuracy: 0.3920 - loss: 2.1726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejas\\anaconda3\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73964, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1807s\u001b[0m 821ms/step - accuracy: 0.3921 - loss: 2.1723 - val_accuracy: 0.7396 - val_loss: 0.8272\n",
      "Epoch 2/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649ms/step - accuracy: 0.7720 - loss: 0.7365\n",
      "Epoch 2: val_accuracy improved from 0.73964 to 0.87548, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1620s\u001b[0m 737ms/step - accuracy: 0.7720 - loss: 0.7365 - val_accuracy: 0.8755 - val_loss: 0.3862\n",
      "Epoch 3/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626ms/step - accuracy: 0.8305 - loss: 0.5363\n",
      "Epoch 3: val_accuracy improved from 0.87548 to 0.89677, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1551s\u001b[0m 706ms/step - accuracy: 0.8305 - loss: 0.5363 - val_accuracy: 0.8968 - val_loss: 0.3204\n",
      "Epoch 4/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779ms/step - accuracy: 0.8566 - loss: 0.4446\n",
      "Epoch 4: val_accuracy improved from 0.89677 to 0.90838, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1829s\u001b[0m 832ms/step - accuracy: 0.8566 - loss: 0.4446 - val_accuracy: 0.9084 - val_loss: 0.2771\n",
      "Epoch 5/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675ms/step - accuracy: 0.8783 - loss: 0.3803\n",
      "Epoch 5: val_accuracy improved from 0.90838 to 0.91162, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1778s\u001b[0m 809ms/step - accuracy: 0.8783 - loss: 0.3803 - val_accuracy: 0.9116 - val_loss: 0.2697\n",
      "Epoch 6/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966ms/step - accuracy: 0.8942 - loss: 0.3278\n",
      "Epoch 6: val_accuracy improved from 0.91162 to 0.92329, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2349s\u001b[0m 1s/step - accuracy: 0.8942 - loss: 0.3278 - val_accuracy: 0.9233 - val_loss: 0.2285\n",
      "Epoch 7/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.9033 - loss: 0.3029\n",
      "Epoch 7: val_accuracy improved from 0.92329 to 0.93814, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1516s\u001b[0m 690ms/step - accuracy: 0.9033 - loss: 0.3029 - val_accuracy: 0.9381 - val_loss: 0.1931\n",
      "Epoch 8/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678ms/step - accuracy: 0.9081 - loss: 0.2860\n",
      "Epoch 8: val_accuracy did not improve from 0.93814\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1673s\u001b[0m 762ms/step - accuracy: 0.9081 - loss: 0.2860 - val_accuracy: 0.9363 - val_loss: 0.1914\n",
      "Epoch 9/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9143 - loss: 0.2668\n",
      "Epoch 9: val_accuracy improved from 0.93814 to 0.94332, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1517s\u001b[0m 690ms/step - accuracy: 0.9143 - loss: 0.2668 - val_accuracy: 0.9433 - val_loss: 0.1772\n",
      "Epoch 10/10\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600ms/step - accuracy: 0.9226 - loss: 0.2403\n",
      "Epoch 10: val_accuracy improved from 0.94332 to 0.94781, saving model to plant_disease_model.keras\n",
      "\u001b[1m2197/2197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1526s\u001b[0m 695ms/step - accuracy: 0.9226 - loss: 0.2403 - val_accuracy: 0.9478 - val_loss: 0.1636\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Paths to dataset directories\n",
    "train_data_dir = \"D:/MCA/Project/plant_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
    "validation_data_dir = \"D:/MCA/Project/plant_dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n",
    "\n",
    "# Set up image generators for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize pixel values to [0, 1]\n",
    "    shear_range=0.2,  # Shear transformation\n",
    "    zoom_range=0.2,  # Random zoom\n",
    "    horizontal_flip=True  # Random horizontal flip\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)  # Normalize pixel values\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(128, 128),  # Resize images\n",
    "    batch_size=32,  # Number of images per batch\n",
    "    class_mode='categorical'  # Use categorical labels\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(train_generator.num_classes, activation='softmax')  # Use number of classes in the dataset\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define a ModelCheckpoint callback to save the best model in .keras format\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"plant_disease_model.keras\",  # File to save the best model\n",
    "    monitor=\"val_accuracy\",  # Monitor validation accuracy\n",
    "    verbose=1,  # Log messages when saving\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    mode=\"max\"  # Maximize validation accuracy\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dde1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
